{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1t0_4BxEJ0XncyYvn_VyEQhxwNMvtSUNx?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dgib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdgib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DGIB, ExtractorMLP, Discriminator\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_data_loaders, get_model, set_seed, CriterionClf, CriterionRecon, init_metric_dict, load_checkpoint\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_one_epoch, update_best_epoch_res, get_viz_idx, visualize_results\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dgib'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from dgib import DGIB, ExtractorMLP, Discriminator\n",
    "from utils import get_data_loaders, get_model, set_seed, CriterionClf, CriterionRecon, init_metric_dict, load_checkpoint\n",
    "from trainer import run_one_epoch, update_best_epoch_res, get_viz_idx, visualize_results\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_name = 'ba_2motifs'\n",
    "# dataset_name = 'mutag'\n",
    "# model_name = 'GIN'\n",
    "\n",
    "dataset_name = 'ImageMagick'\n",
    "model_name = 'PNA'\n",
    "\n",
    "method_name = 'DGIB'\n",
    "cuda_id = 0\n",
    "seed = 0\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data')\n",
    "device = torch.device(f'cuda:{cuda_id}' if cuda_id >= 0 else 'cpu')\n",
    "\n",
    "if model_name == 'GIN':\n",
    "    model_config = {'model_name': 'GIN', 'hidden_size': 80, 'n_layers': 2, 'dropout_p': 0.3, 'use_edge_attr': True}\n",
    "elif model_name == 'PNA':\n",
    "    model_config = {'model_name': 'PNA', 'hidden_size': 80, 'n_layers': 4, 'dropout_p': 0.3, 'use_edge_attr': False, \n",
    "                    'atom_encoder': False, 'aggregators': ['mean', 'min', 'max', 'std'], 'scalers': False}\n",
    "else:\n",
    "    assert model_name == 'RGCN'\n",
    "    model_config = {'model_name': 'RGCN', 'hidden_size': 64, 'n_layers': 2, 'dropout_p': 0.3, 'use_edge_attr': False}\n",
    "metric_dict = deepcopy(init_metric_dict)\n",
    "model_dir = data_dir / dataset_name / 'logs' / (datetime.now().strftime(\"%m_%d_%Y-%H_%M_%S\") + '-' + dataset_name + '-' + model_name + '-seed' + str(seed) + '-' + method_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders, test_set, x_dim, edge_attr_dim, num_class, aux_info = get_data_loaders(data_dir, dataset_name, batch_size=128, random_state=seed,\n",
    "                                                                                splits={'train': 0.8, 'valid': 0.1, 'test': 0.1}, mode='common', parameters=None,\n",
    "                                                                                mutag_x=True if dataset_name == 'mutag' else False)\n",
    "model_config['deg'] = aux_info['deg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_set[0].num_relations)\n",
    "print(aux_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_t = get_model(x_dim, edge_attr_dim, num_class, aux_info['multi_label'], model_config, device, aux_info.get('num_relations', None))\n",
    "gnn_s = get_model(x_dim, edge_attr_dim, num_class, aux_info['multi_label'], model_config, device, aux_info.get('num_relations', None))\n",
    "extractor = ExtractorMLP(model_config['hidden_size'], learn_edge_att=False).to(device)\n",
    "discriminator = Discriminator(model_config['hidden_size']).to(device)\n",
    "optimizer = torch.optim.Adam(list(extractor.parameters()) + list(gnn_t.parameters()) + list(gnn_s.parameters()) + list(discriminator.parameters()), lr=1e-3, weight_decay=3.0e-6)\n",
    "criterion_clf = CriterionClf(num_class, aux_info['multi_label'])\n",
    "criterion_recon = CriterionRecon()\n",
    "dgib = DGIB(gnn_t, gnn_s, extractor, discriminator, criterion_clf, criterion_recon, optimizer, learn_edge_att=False, final_r=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(loaders['train'].__dict__)\n",
    "for batch in loaders['train']:\n",
    "    print(batch)\n",
    "    \"\"\" print(batch.edge_index)\n",
    "    print(batch.batch) \"\"\"\n",
    "    \"\"\" print(len(batch))\n",
    "    print(batch)\n",
    "print(aux_info['multi_label'])\n",
    "print(criterion_clf.multi_label) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import numpy as np\n",
    "array1=batch.edge_index.numpy()\n",
    "array2=batch.batch.numpy()\n",
    "with open('tensors.txt', 'w') as f:\n",
    "    # 将第一个tensor保存到文件\n",
    "    np.savetxt(f, array1, fmt='%d', header='Tensor 1', comments='')\n",
    "    \n",
    "    # 添加一个空行作为分隔符\n",
    "    f.write('\\n')\n",
    "    \n",
    "    # 将第二个tensor保存到文件\n",
    "    np.savetxt(f, array2, fmt='%d', header='Tensor 2', comments='') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)\n",
    "for epoch in range(200):\n",
    "    train_res = run_one_epoch(dgib, loaders['train'], epoch, 'train', dataset_name, seed, model_config['use_edge_attr'], aux_info['multi_label'])\n",
    "    valid_res = run_one_epoch(dgib, loaders['valid'], epoch, 'valid', dataset_name, seed, model_config['use_edge_attr'], aux_info['multi_label'])\n",
    "    test_res = run_one_epoch(dgib, loaders['test'], epoch, 'test', dataset_name, seed, model_config['use_edge_attr'], aux_info['multi_label'])\n",
    "    \n",
    "    metric_dict = update_best_epoch_res(dgib, train_res, valid_res, test_res, metric_dict, dataset_name, epoch, model_dir)\n",
    "    print(f'[Seed {seed}, Epoch: {epoch}]: Best Epoch: {metric_dict[\"metric/best_clf_epoch\"]}, '\n",
    "          f'Best Val Pred ACC/ROC: {metric_dict[\"metric/best_clf_valid\"]:.3f}, Best Test Pred ACC/ROC: {metric_dict[\"metric/best_clf_test\"]:.3f}, '\n",
    "          f'Best Test X AUROC: {metric_dict[\"metric/best_x_roc_test\"]:.3f}')\n",
    "    print('='*50)\n",
    "    print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = metric_dict['metric/best_clf_epoch']\n",
    "load_checkpoint(dgib, model_dir, model_name=f'dgib_epoch_{best_epoch}', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_viz_samples = 10\n",
    "assert aux_info['multi_label'] is False\n",
    "\n",
    "all_viz_set = get_viz_idx(test_set, dataset_name, num_viz_samples)\n",
    "visualize_results(dgib, all_viz_set, test_set, num_viz_samples, dataset_name, model_config['use_edge_attr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_viz_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e720c5032519bc7b462f7dd8f9fcb5b822f5f0841038515fb417505bb6503a4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('gnn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
